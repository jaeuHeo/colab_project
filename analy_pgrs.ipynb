{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "analy_pgrs.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyP6UPFVafVbOeHwgDq5ERzv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaeuHeo/colab_project/blob/main/analy_pgrs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dsaxck8mPhm5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NT9D8PpR_qaC"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_n_PhLB9Qdq7"
      },
      "source": [
        "train = pd.read_csv('/content/drive/My Drive/prgs/train.csv')\n",
        "job_companies = pd.read_csv('/content/drive/My Drive/prgs/job_companies.csv')\n",
        "job_tags = pd.read_csv('/content/drive/My Drive/prgs/job_tags.csv')\n",
        "tags = pd.read_csv('/content/drive/My Drive/prgs/tags.csv')\n",
        "test_job = pd.read_csv('/content/drive/My Drive/prgs/test_job.csv')\n",
        "user_tags = pd.read_csv('/content/drive/My Drive/prgs/user_tags.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzsiQw1tP51n"
      },
      "source": [
        "job_companies['companySize'] = job_companies['companySize'].fillna(0)\n",
        "job_companies['companySize']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91BUPZBjPofT"
      },
      "source": [
        "job_com = job_companies[['jobID','companySize']]\n",
        "companySize = []\n",
        "# job_com\n",
        "for tr in train['jobID'].values:\n",
        "    \n",
        "    for job,com in job_com.values:\n",
        "        \n",
        "        if tr == job:    \n",
        "            \n",
        "            companySize.append(com)\n",
        "        else:\n",
        "            pass\n",
        "train['companySize'] = companySize\n",
        "print(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LYOtJPmE5y6"
      },
      "source": [
        "train.companySize.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7_eqaddQsFW"
      },
      "source": [
        "size_dic = {'1-10' : 1,'11-50' : 2, '51-100':3,'101-200':4,'201-500':5,'501-1000':6,'1000 이상':7}\n",
        "\n",
        "for tra in train.companySize.values:\n",
        "    for key,val in size_dic.items():\n",
        "        # print(key,val)\n",
        "        if tra == key:\n",
        "            train = train.replace(tra,val)\n",
        "            # tra = val\n",
        "        else:\n",
        "            pass\n",
        "train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCbtKKNEQzV7"
      },
      "source": [
        "train = pd.get_dummies(data = train, columns = ['companySize'], prefix = 'companySize')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGsxk9RrQ2Dm"
      },
      "source": [
        "train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwlkjgn9Q3kq"
      },
      "source": [
        "# jobtags = []\n",
        "# # job_com\n",
        "# for job,tag in job_tags.values:\n",
        "    \n",
        "#     for tai,key in tags.values:\n",
        "        \n",
        "#         if tag == tai:    \n",
        "            \n",
        "#             jobtags.append(key)\n",
        "#         else:\n",
        "#             pass\n",
        "# job_tags['keyword'] = jobtags\n",
        "# print(job_tags)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ui4K58TKQ654"
      },
      "source": [
        "# usertags = []\n",
        "# # job_com\n",
        "# for job,tag in user_tags.values:\n",
        "    \n",
        "#     for tai,key in tags.values:\n",
        "        \n",
        "#         if tag == tai:    \n",
        "            \n",
        "#             usertags.append(key)\n",
        "#         else:\n",
        "#             pass\n",
        "# user_tags['keyword'] = usertags\n",
        "# print(user_tags)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECHRfEmvQ-Ez"
      },
      "source": [
        "# same_key = []\n",
        "# for job,tag in zip(job_tags['jobID'],job_tags['keyword']):\n",
        "    \n",
        "#     for use,tad in zip(user_tags['userID'],user_tags['keyword']):\n",
        "        \n",
        "#         if tag == tad:\n",
        "#             semi_same = []\n",
        "#             semi_same.append(use)\n",
        "#             semi_same.append(job)\n",
        "#             semi_same.append(tad)\n",
        "#             same_key.append(semi_same)\n",
        "#         else:\n",
        "#             pass\n",
        "# same_key"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbiJSidXRCPA"
      },
      "source": [
        "# new_key = []\n",
        "# for v in same_key:\n",
        "#     if v not in new_key:\n",
        "#         new_key.append(v)\n",
        "# print(new_key)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Df98HGOSRKhN"
      },
      "source": [
        "# new_key"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biSwLuAwnLKw"
      },
      "source": [
        "# keyword_tr = []\n",
        "# for user, job,k in new_key:\n",
        "#     for use,jo in zip(train['userID'],train['jobID']):\n",
        "#         if user == use and job == jo:\n",
        "#             keyword_tr.append(k)\n",
        "# train['keyword'] = keyword_tr\n",
        "# train\n",
        "# columns = ['userID','jobID','keyword']\n",
        "# key_df = pd.DataFrame(new_key, columns=columns)\n",
        "# key_df = pd.get_dummies(data = key_df, columns = ['keyword'], prefix = 'keyword')\n",
        "# key_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFXA83M9oDry"
      },
      "source": [
        "target = train['applied']\n",
        "train_data = train.drop('applied', axis=1)\n",
        "train_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0G99q_zy32ao"
      },
      "source": [
        "user_code = []\n",
        "user_con =[]\n",
        "count = 1\n",
        "for cod in train_data['userID']:\n",
        "    # print(cod)\n",
        "    \n",
        "    if cod not in user_code:\n",
        "\n",
        "        user_code.append(cod)\n",
        "        user_con.append(count)\n",
        "        count += 1\n",
        "    # else:\n",
        "    #     user_code.append(count)\n",
        "    #     user_con.append('overcount')\n",
        "\n",
        "print(f'usercode: {user_code} \\n usercount: {user_con}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIi-Ao28IsfH"
      },
      "source": [
        "user_dic = dict(zip(user_code,user_con))\n",
        "user_dic\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Its5ins5JG3V"
      },
      "source": [
        "# for data in train_data:\n",
        "train_data['userID'] = train_data['userID'].map(user_dic)\n",
        "train_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHnLViMWeAaw"
      },
      "source": [
        "job_code = []\n",
        "job_con =[]\n",
        "count_j = 1\n",
        "for job in train_data['jobID']:\n",
        "    # print(cod)\n",
        "    \n",
        "    if job not in job_code:\n",
        "\n",
        "        job_code.append(job)\n",
        "        job_con.append(count_j)\n",
        "        count_j += 1\n",
        "    # else:\n",
        "    #     user_code.append(count)\n",
        "    #     user_con.append('overcount')\n",
        "\n",
        "print(f'jobcode: {job_code} \\n jobcount: {job_con}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTw7yuameibs"
      },
      "source": [
        "job_dic = dict(zip(job_code,job_con))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAYX4Uzmeikl"
      },
      "source": [
        "\n",
        "train_data['jobID'] = train_data['jobID'].map(job_dic)\n",
        "train_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ek6f49qq7rF"
      },
      "source": [
        "from xgboost import plot_importance\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import KFold,GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "k_fold = KFold(n_splits =5, shuffle=True, random_state = 12)\n",
        "xgb = XGBClassifier()\n",
        "xgb_param_grid = {'n_estimators':[100,200,300,400,500],\n",
        "                 'learning_rate': [0.1, 0.01, 0.05, 0.2],\n",
        "                 'max_depth': [4,8,12,16]}\n",
        "xgb_grid = GridSearchCV(xgb, param_grid = xgb_param_grid,cv=5,scoring='accuracy', n_jobs=-1,verbose=1)\n",
        "xgb_grid.fit(train_data,target)\n",
        "scores_df = pd.DataFrame(xgb_grid.cv_results_)\n",
        "print(scores_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGoVDvUD180T"
      },
      "source": [
        "print(f'best_param: {xgb_grid.best_params_}')\n",
        "print(f'best_acc : {xgb_grid.best_score_}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqpaCuC3hzOm"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "clf = SVC()\n",
        "scoring = 'accuracy'\n",
        "score = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aG5Yu5rAvYHo"
      },
      "source": [
        "import numpy as np\n",
        "print(np.mean(score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "455_MlXGh8t7"
      },
      "source": [
        "from lightgbm import LGBMClassifier,plot_importance\n",
        "lgb = LGBMClassifier(feature_fraction = 0.8,num_leaves = 80)\n",
        "lgb_param_grid = {'n_estimators':[100,300,500],\n",
        "                 'learning_rate': [0.1, 0.01, 0.03],\n",
        "                 'max_depth': [4,8,15,50],\n",
        "                  'feature_fraction': [0.8,0.9]\n",
        "                  }\n",
        "lgb_grid = GridSearchCV(lgb, param_grid = lgb_param_grid,cv=5,scoring='accuracy', n_jobs=-1,verbose=1)\n",
        "lgb_grid.fit(train_data,target)\n",
        "scores_lgb = pd.DataFrame(lgb_grid.cv_results_)\n",
        "print(scores_lgb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fcn_s1zkku_D"
      },
      "source": [
        "print(f'best_param: {lgb_grid.best_params_}')\n",
        "print(f'best_acc : {lgb_grid.best_score_}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVBuonRqpdQw"
      },
      "source": [
        "# test_job\n",
        "companySize_test = []\n",
        "# job_com\n",
        "for tr in test_job['jobID'].values:\n",
        "    \n",
        "    for job,com in job_com.values:\n",
        "        \n",
        "        if tr == job:    \n",
        "            \n",
        "            companySize_test.append(com)\n",
        "        else:\n",
        "            pass\n",
        "test_job['companySize'] = companySize_test\n",
        "print(test_job)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWCOesptp_Ih"
      },
      "source": [
        "test_job = test_job.replace({'companySize':change_dic })\n",
        "test_job"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZt0hw9UqLnv"
      },
      "source": [
        "test_job = pd.get_dummies(data = test_job, columns = ['companySize'], prefix = 'companySize')\n",
        "test_job"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pGQTnPlr9oT"
      },
      "source": [
        "test_job['userID']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_r52b3SqZEM"
      },
      "source": [
        "user_code_test = []\n",
        "user_con_test =[]\n",
        "count_t = 1\n",
        "for uct in test_job['userID']:\n",
        "    # print(uct)\n",
        "    \n",
        "    if uct not in user_code_test:\n",
        "\n",
        "        user_code_test.append(uct)\n",
        "        user_con_test.append(count_t)\n",
        "        count_t += 1\n",
        "    # else:\n",
        "    #     user_code.append(count)\n",
        "    #     user_con.append('overcount')\n",
        "\n",
        "print(f'usercode: {user_code_test} \\n usercount: {user_con_test}')\n",
        "# test_job['userID'] = test_job['userID'].map(user_dic)\n",
        "# test_job['jobID'] = test_job['jobID'].map(job_dic)\n",
        "# test_job.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR7LTl47q0CQ"
      },
      "source": [
        "usertest_dic = dict(zip(user_code_test,user_con_test))\n",
        "# user_dic\n",
        "test_job['userID'] = test_job['userID'].map(usertest_dic)\n",
        "test_job"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2sgptaPwswb"
      },
      "source": [
        "job_code_t = []\n",
        "job_con_t =[]\n",
        "jobcount_t = 1\n",
        "for jobs in test_job['jobID']:\n",
        "    # print(cod)\n",
        "    \n",
        "    if jobs not in job_code_t:\n",
        "\n",
        "        job_code_t.append(jobs)\n",
        "        job_con_t.append(jobcount_t)\n",
        "        jobcount_t += 1\n",
        "    # else:\n",
        "    #     user_code.append(count)\n",
        "    #     user_con.append('overcount')\n",
        "\n",
        "print(f'jobcode: {job_code_t} \\n jobcount: {job_con_t}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OELCoD0gxG8L"
      },
      "source": [
        "jobtest_dic = dict(zip(job_code_t,job_con_t))\n",
        "# user_dic\n",
        "test_job['jobID'] = test_job['jobID'].map(jobtest_dic)\n",
        "test_job"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYgWR0HqxRGj"
      },
      "source": [
        "test_job.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjqubikdxUeg"
      },
      "source": [
        "prediction = lgb_grid.predict(test_job)\n",
        "prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3_KCFN4xlr7"
      },
      "source": [
        "submission = pd.DataFrame({\n",
        "    'applied': prediction\n",
        "})\n",
        "submission.to_csv('submission_prgs.csv',index=False)\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hU0uvlYvyoPg"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('submission_prgs.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXp2uIjAysXp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}