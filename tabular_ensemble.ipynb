{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tabular_ensemble.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMx1pNfyUJdM87J7NtiUkqY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaeuHeo/colab_project/blob/main/tabular_ensemble.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sa05EdJKsjjx"
      },
      "source": [
        "# Basic Imports \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Plotting \n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "# Preprocessing\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Metrics \n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "# ML Models\n",
        "import lightgbm as lgb\n",
        "from lightgbm import LGBMRegressor \n",
        "import xgboost as xg \n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn import svm\n",
        "\n",
        "# Ignore Warnings \n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#drive uproad\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wu2E6TthatMO"
      },
      "source": [
        "!pip install shap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4M1DzLbbAAG"
      },
      "source": [
        "!pip install Bayesian-Optimization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YpME93AaqEd"
      },
      "source": [
        "# Feature Importance \n",
        "# import shap\n",
        "\n",
        "# Model Tuning \n",
        "from bayes_opt import BayesianOptimization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2STjFIFsprO"
      },
      "source": [
        "train = pd.read_csv('/content/drive/My Drive//tabular/train.csv')\n",
        "test = pd.read_csv('/content/drive/My Drive//tabular/test.csv')\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MI2nvvFNtI_j"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise SystemError('GPU device not found')\n",
        "\n",
        "def cpu():\n",
        "  with tf.device('/cpu:0'):\n",
        "    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
        "    return tf.math.reduce_sum(net_cpu)\n",
        "\n",
        "def gpu():\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
        "    return tf.math.reduce_sum(net_gpu)\n",
        "  \n",
        "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
        "cpu()\n",
        "gpu()\n",
        "\n",
        "# Run the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PpcCGcqtLrq"
      },
      "source": [
        "train.describe()\n",
        "train.isnull().sum()\n",
        "train.corr(method='pearson')\n",
        "#heatmap으로 상관관계를 표시\n",
        "import seaborn as sb\n",
        "plt.rcParams[\"figure.figsize\"] = (40,40)\n",
        "sb.heatmap(train.corr(),\n",
        "           annot = True, #실제 값 화면에 나타내기\n",
        "           cmap = 'Greens', #색상\n",
        "           vmin = -1, vmax=1 , #컬러차트 영역 -1 ~ +1\n",
        "          )\n",
        "#선형회귀\n",
        "import statsmodels.api as sm\n",
        "multi_model = sm.OLS(y_train, x_train)\n",
        "fitted_multi_model = multi_model.fit()\n",
        "fitted_multi_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvzx89NlthEV"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from collections import defaultdict\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler,RobustScaler\n",
        "class Preprocessor():\n",
        "    def __init__(self):\n",
        "        self.en_dic = None\n",
        "        self.standard_scaler = None\n",
        "        self.num_cols = None\n",
        "        self.cat_cols = None\n",
        "        # self.test_cats_onehot,self.test_onehot_cols = self.cats_onehot(test_cats_en)\n",
        "    def preprocess(self,data_df,train=True,combine_min_cats=False, add_pca_feats=False):\n",
        "\n",
        "        if train:\n",
        "            self.train_ids = data_df.loc[:, 'id']\n",
        "            train_cats = data_df.loc[:, data_df.dtypes == object]\n",
        "            self.cat_cols = train_cats.columns\n",
        "\n",
        "            if combine_min_cats:\n",
        "                self._find_minority_cats(train_cats)\n",
        "                train_cats = self._combine_minority_feats(train_cats)\n",
        "\n",
        "            self.en_dic = defaultdict(LabelEncoder)\n",
        "            train_cats_en = train_cats.apply(lambda x: self.en_dic[x.name].fit_transform(x))\n",
        "            tr_cats_onehot,tr_onehot_cols = self.cats_onehot(train_cats_en)\n",
        "            \n",
        "            train_num = data_df.loc[:,data_df.dtypes != object].drop(columns=['target','id'])\n",
        "            self.num_cols = train_num.columns\n",
        "            self.Robust_Scaler = RobustScaler()\n",
        "            train_num_scaler = self.Robust_Scaler.fit_transform(train_num)\n",
        "\n",
        "            if add_pca_feats:\n",
        "                pca_feats = self._return_num_pca(train_num_scaler)\n",
        "                X = pd.DataFrame(np.hstack((train_cats_en,pca_feats)),columns=list(train_cats_en)+list(self.pca_cols))\n",
        "            else:\n",
        "                X = pd.DataFrame(np.hstack((train_cats_en,train_num_scaler)),columns = list(train_cats_en)+list(self.num_cols))\n",
        "\n",
        "        else:\n",
        "            self.test_ids = data_df.loc[:,'id']\n",
        "            test_cats = data_df.loc[:, self.cat_cols]\n",
        "            if combine_min_cats:\n",
        "                self._find_minority_cats(test_cats)\n",
        "                test_cats = self._combine_minority_feats(test_cats)\n",
        "                \n",
        "            test_cats_en = test_cats.apply(lambda x: self.en_dic[x.name].fit_transform(x))\n",
        "            test_cats_onehot,test_onehot_cols = self.cats_onehot(test_cats_en)\n",
        "            test_num = data_df.loc[:,self.num_cols]\n",
        "            test_num_scaler = self.Robust_Scaler.fit_transform(test_num)\n",
        "\n",
        "            if add_pca_feats:\n",
        "                pca_feats = self._return_num_pca(test_num_scaler,train=False)\n",
        "\n",
        "                X = pd.DataFrame(np.hstack((test_cats_en,pca_feats)),columns = list(test_cats_en)+list(self.pca_cols))\n",
        "            \n",
        "            else:\n",
        "                X = pd.DataFrame(np.hstack((test_cats_en,test_num_scaler)),columns = list(test_cats_en)+list(self.num_cols))\n",
        "\n",
        "        return X\n",
        "\n",
        "    def cats_onehot(self,data_df):\n",
        "        self.cats_df = pd.get_dummies(data=data_df,columns=self.cat_cols, prefix= self.cat_cols)\n",
        "        self.cats_onehot_cols = self.cats_df.columns\n",
        "        return self.cats_df, self.cats_onehot_cols\n",
        "   \n",
        "    def _find_minority_cats(self, data_df):\n",
        "        self.composite_category = 'z'\n",
        "        self.threshold = 0.05\n",
        "        self.minority_col_dict = {}\n",
        "        self.minority_map_dic = {}\n",
        "        for feature in self.cat_cols:\n",
        "            self.minority_col_dict[feature] = []\n",
        "            self.minority_map_dic[feature] = {}\n",
        "            \n",
        "            for category,proportion in data_df[feature].value_counts(normalize=True).iteritems():\n",
        "                if proportion < self.threshold:\n",
        "                    self.minority_col_dict[feature].append(category)\n",
        "                    self.minority_map_dic[feature] = { x : self.composite_category for x in self.minority_col_dict[feature]}\n",
        "        return self.minority_map_dic, self.minority_col_dict\n",
        "    \n",
        "    def _combine_minority_feats(self, data_df, replace = False):\n",
        "        new_df = data_df.copy()\n",
        "        for feat in self.cat_cols:\n",
        "            col_label = f\"{feat}\" if replace else f\"{feat}_new\"\n",
        "            new_df[feat] = new_df[feat].replace(self.minority_map_dic[feat])\n",
        "        return new_df\n",
        "\n",
        "    def _return_num_pca(self,num_df,train=True):\n",
        "        self.n_components = 0.85\n",
        "        if train:\n",
        "            self.pca = PCA(n_components = self.n_components)\n",
        "            \n",
        "            num_rd = self.pca.fit_transform(num_df)\n",
        "            print(f'pca_explain: {self.pca.explained_variance_ratio_}')\n",
        "            self.pca_cols = [f'pca_{x}' for x in range(num_rd.shape[1])]\n",
        "\n",
        "        else:\n",
        "            num_rd = self.pca.transform(num_df)\n",
        "\n",
        "            self.pca_cols = [f'pca_{x}' for x in range(num_rd.shape[1])]\n",
        "        \n",
        "        return pd.DataFrame(num_rd, columns = self.pca_cols)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PS577vQ0tkO0"
      },
      "source": [
        "data_proc = Preprocessor()\n",
        "X = data_proc.preprocess(train, combine_min_cats=False, add_pca_feats=False)\n",
        "y = train.loc[:, 'target']\n",
        "X_test = data_proc.preprocess(test,train=False,combine_min_cats=False, add_pca_feats=False)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "print(X.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaooHdE-mEu9"
      },
      "source": [
        "print(f'xshape: {X.shape} \\n yshape: {y.shape} \\n X_test: {X_test.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaXJi3qqmiPD"
      },
      "source": [
        "display(X.isnull().sum())\n",
        "display(y.isnull().sum())\n",
        "display(X_test.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FLGvxwhtmnM"
      },
      "source": [
        "def score_log(df:pd.DataFrame, seed: int, num_fold: int, model_name: str, cv:float):\n",
        "    score_dict = {'seed':seed, 'fold': num_fold, 'model': model_name, 'cv': cv}\n",
        "    df = pd.concat([df, pd.DataFrame.from_dict([score_dict])])\n",
        "    print(df)\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwmOlu1pCyas"
      },
      "source": [
        "\n",
        "cat_features = [f'cat{i}' for i in range(10)]\n",
        "oof = np.zeros(X.shape[0])\n",
        "preds = 0\n",
        "score_df = pd.DataFrame()\n",
        "feature_importance = pd.DataFrame()\n",
        "SEED = 2021\n",
        "kf = KFold(n_splits=5,shuffle =True, random_state=SEED)\n",
        "rf_params = {'random_state': SEED,\n",
        "          'metric': 'rmse',\n",
        "          'n_estimators': 30000,\n",
        "          'n_jobs': -1,\n",
        "          'cat_feature': [x for x in range(len(cat_features))],\n",
        "          'bagging_seed': SEED,\n",
        "          'feature_fraction_seed': SEED,\n",
        "          'learning_rate': 0.003899156646724397,\n",
        "          'max_depth': 99,\n",
        "          'num_leaves': 63,\n",
        "          'reg_alpha': 9.562925363678952,\n",
        "          'reg_lambda': 9.355810045480153,\n",
        "          'colsample_bytree': 0.2256038826485174,\n",
        "          'min_child_samples': 290,\n",
        "          'subsample_freq': 1,\n",
        "          'subsample': 0.8805303688019942,\n",
        "          'max_bin': 882,\n",
        "          'min_data_per_group': 127,\n",
        "          'cat_smooth': 96,\n",
        "          'cat_l2': 19}\n",
        "for fold,(train_idx,val_idx) in enumerate(kf.split(X=X)):\n",
        "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
        "\n",
        "    model_lgbm = LGBMRegressor(**rf_params)\n",
        "    model_lgbm.fit(X_train,y_train, eval_set=[(X_val, y_val)],\n",
        "                  eval_metric='rmse',\n",
        "                  early_stopping_rounds=100,\n",
        "                  verbose=2)\n",
        "    \n",
        "    tmp = pd.DataFrame()\n",
        "    # tmp['feature'] = model_lgbm.feature_name_\n",
        "    # tmp['importance'] = model_lgbm.feature_importances_\n",
        "    # tmp['fold'] = fold\n",
        "    # tmp['seed'] = SEED\n",
        "    # feature_importances = feature_importances.append(tmp)\n",
        "\n",
        "    oof[val_idx] = model_lgbm.predict(X_val)\n",
        "    # preds += model_rf.predict(test_df)/5\n",
        "    rmse = mean_squared_error(y_val, oof[val_idx], squared=False)\n",
        "    score_df = score_log(score_df, SEED, fold, 'lgb', rmse)\n",
        "    print(f\"rmse {rmse}\")\n",
        "print('*'*100)\n",
        "print(score_df)\n",
        "    \n",
        "    \n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyPQaKi8tuiC"
      },
      "source": [
        "model_lgbm.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OcZh9-MuBBW"
      },
      "source": [
        "preds = model_lgbm.predict(X_test)\n",
        "preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-W87OkGzuHr"
      },
      "source": [
        "preds = pd.DataFrame(preds)\n",
        "preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMG8Hm9_z1ee"
      },
      "source": [
        "preds.to_csv('tabular_Pseudo Labelling.csv',index=False)\n",
        "!ls\n",
        "from google.colab import files\n",
        "files.download('tabular_Pseudo Labelling.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6OuNbn0Z_i8"
      },
      "source": [
        "!pip install optuna"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdO22DRTveSr"
      },
      "source": [
        "import optuna\n",
        "\n",
        "original_train = train\n",
        "#test\n",
        "test_target = pd.read_csv('/content/drive/My Drive//tabular/tabular_Pseudo Labelling.csv')\n",
        "test_target\n",
        "test['target'] = test_target\n",
        "test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMq-LxyXxFLb"
      },
      "source": [
        "train = pd.concat([original_train,test],axis=0)\n",
        "train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvAuNM3v0S5F"
      },
      "source": [
        "id_feature = ['id']\n",
        "cont_features = [f'cont{i}' for i in range(14)]\n",
        "cat_features = [f'cat{i}' for i in range(10)]\n",
        "target_feature = ['target']\n",
        "all_features = id_feature + cat_features + cont_features + target_feature\n",
        "\n",
        "target = train[target_feature]\n",
        "train_df = train[all_features]\n",
        "test_df = test[all_features]\n",
        "test_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Hy2MZenGdPd"
      },
      "source": [
        "train_x = data_proc.preprocess(train_df, combine_min_cats=False, add_pca_feats=False)\n",
        "train_y = target\n",
        "test_x = data_proc.preprocess(test_df,train=False,combine_min_cats=False, add_pca_feats=False)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "print(test_x.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DABASpvVKWHj"
      },
      "source": [
        "import optuna\n",
        "import sklearn\n",
        "from sklearn.model_selection import cross_val_score\n",
        "def objective(trial):\n",
        "\n",
        "    n_estimators = trial.suggest_int('n_estimators',20000,30000)\n",
        "    # cat_feature = [x for x in range(len(cat_features))]\n",
        "    learning_rate = trial.suggest_loguniform('learning_rate',0.001,0.01)\n",
        "    max_depth = trial.suggest_int('max_depth',1,100)\n",
        "    num_leaves = trial.suggest_int('num_leaves',1,100)\n",
        "    reg_alpha = trial.suggest_loguniform('reg_alpha',1,10)\n",
        "    reg_lambda = trial.suggest_loguniform('reg_lambda',1,10)\n",
        "    colsample_bytree = trial.suggest_loguniform('colsample_bytree',0.01,0.99)\n",
        "    min_child_samples = trial.suggest_int('min_child_samples',1,500)\n",
        "    subsample = trial.suggest_loguniform('subsample',0.01,0.99)\n",
        "\n",
        "    regrs = LGBMRegressor(n_estimators=n_estimators,learning_rate=learning_rate,\n",
        "                         max_depth=max_depth, num_leaves=num_leaves,reg_alpha=reg_alpha,\n",
        "                          reg_lambda=reg_lambda,colsample_bytree=colsample_bytree,\n",
        "                          min_child_samples=min_child_samples,subsample=subsample)\n",
        "    cross_score = cross_val_score(regrs,train_x,train_y,n_jobs=-1,scoring='neg_mean_squared_error' ,cv=5)\n",
        "    rmse_scores = np.sqrt(-cross_score)\n",
        "    return rmse_scores.mean()\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=10)\n",
        "trial = study.best_trial\n",
        "\n",
        "print(f'rmse: {trial.value}')\n",
        "print(f'best_params: {trial.params}')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeDMbTNpNbJN"
      },
      "source": [
        "final_oof = np.zeros(X.shape[0])\n",
        "final_preds = 0\n",
        "final_score_df = pd.DataFrame()\n",
        "feature_importance = pd.DataFrame()\n",
        "fi_SEED = 1234\n",
        "kf = KFold(n_splits=5,shuffle =True, random_state=fi_SEED)\n",
        "rf_params = {'random_state': fi_SEED,\n",
        "          'metric': 'rmse',\n",
        "          'n_estimators': 22294,\n",
        "          'n_jobs': -1,\n",
        "          'cat_feature': [x for x in range(len(cat_features))],\n",
        "          'bagging_seed': fi_SEED,\n",
        "          'feature_fraction_seed': fi_SEED,\n",
        "          'learning_rate': 0.0022862168892729263,\n",
        "          'max_depth': 54,\n",
        "          'num_leaves': 46,\n",
        "          'reg_alpha': 1.1244285255428748,\n",
        "          'reg_lambda': 3.163004564816904,\n",
        "          'colsample_bytree': 0.6505855225331759,\n",
        "          'min_child_samples': 352,\n",
        "          'subsample_freq': 1,\n",
        "          'subsample': 0.010450736902586575,\n",
        "          'max_bin': 882,\n",
        "          'min_data_per_group': 127,\n",
        "          'cat_smooth': 96,\n",
        "          'cat_l2': 19}\n",
        "for fold,(train_idx,val_idx) in enumerate(kf.split(X=train_x)):\n",
        "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "    y_train, y_val = train_y.iloc[train_idx], train_y.iloc[val_idx]\n",
        "\n",
        "    fi_lgbm = LGBMRegressor(**rf_params)\n",
        "    fi_lgbm.fit(X_train,y_train, eval_set=[(X_val, y_val)],\n",
        "                  eval_metric='rmse',\n",
        "                  early_stopping_rounds=100,\n",
        "                  verbose=2)\n",
        "    \n",
        "    tmp = pd.DataFrame()\n",
        "    # tmp['feature'] = model_lgbm.feature_name_\n",
        "    # tmp['importance'] = model_lgbm.feature_importances_\n",
        "    # tmp['fold'] = fold\n",
        "    # tmp['seed'] = SEED\n",
        "    # feature_importances = feature_importances.append(tmp)\n",
        "\n",
        "    final_oof[val_idx] = fi_lgbm.predict(X_val)\n",
        "    # preds += model_rf.predict(test_df)/5\n",
        "    rmse = mean_squared_error(y_val, final_oof[val_idx], squared=False)\n",
        "    final_score_df = score_log(final_score_df, fi_SEED, fold, 'lgb', rmse)\n",
        "    print(f\"rmse {rmse}\")\n",
        "print('*'*100)\n",
        "print(final_score_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPGngVpmPdEQ"
      },
      "source": [
        "final_test_pred = fi_lgbm.predict(test_x)\n",
        "final_test_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAlnXYGIt55D"
      },
      "source": [
        "# save submission in csv format\n",
        "submission_df2 = pd.read_csv('/content/drive/My Drive//tabular/sample_submission.csv')\n",
        "submission_df2['target'] = final_test_pred\n",
        "submission_df2.to_csv('submission_tabular_ensemble_final.csv',index=False)\n",
        "!ls\n",
        "from google.colab import files\n",
        "files.download('submission_tabular_ensemble_final.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7C33bA9cL0my"
      },
      "source": [
        "word = 'pyhton'\n",
        "if 'on' in word:\n",
        "    print(True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7swPAj8ntIhz"
      },
      "source": [
        ""
      ]
    }
  ]
}